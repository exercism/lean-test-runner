#!/usr/bin/env sh

# Synopsis:
# Test the test runner by running it against a predefined set of solutions
# with an expected output.

# Output:
# Outputs the diff of the expected test results against the actual test results
# generated by the test runner.

# Example:
# ./bin/run-tests.sh

exit_code=0

solution_file () {
    for file in "${1}"/*.lean; do
        [ "${file}" = *Test.lean ] && continue
        printf '%s\n' "${file}"
        return
    done
}

# Iterate over all test directories
for test_dir in tests/*; do
    test_dir_name=$(basename "${test_dir}")
    test_dir_path=$(realpath "${test_dir}")

    filename=$(solution_file "${test_dir_path}")
    pascal_slug=${filename##*/}
    pascal_slug=${pascal_slug%.lean}
    kebab_slug=$(echo "$pascal_slug" | sed 's/\([A-Z]\)/-\1/g; s/^-//' | tr '[:upper:]' '[:lower:]')

    bin/run.sh "${kebab_slug}" "${test_dir_path}" "${test_dir_path}"

    file="results.json"
    expected_file="expected_${file}"
    echo "${test_dir_name}: comparing ${file} to ${expected_file}"

    # Compare status field (must match exactly)
    actual_status=$(jq -r '.status' "${test_dir_path}/${file}")
    expected_status=$(jq -r '.status' "${test_dir_path}/${expected_file}")

    if [ "${actual_status}" != "${expected_status}" ]; then
        echo "Status mismatch: expected '${expected_status}', got '${actual_status}'"
        exit_code=1
    else
        echo "${test_dir_name}: status OK (${actual_status})"
    fi
done

exit ${exit_code}
